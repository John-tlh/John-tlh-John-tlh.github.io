---
title: 如何对狗和猫的照片进行分类（准确率达到97％）
category: 
- 深度学习
tags: 
- Keras
- Python
---

## 教程概述

1. 狗与猫的预测问题
2. 狗与猫数据集准备
3. 开发基线CNN模型
4. 模型改进
5. 探索迁移学习
6. 如何最终确定模型并做出预测

## 关于猫狗问题

猫狗数据集是指2013年举行的Kaggle机器学习比赛的数据集。该数据集最初用作CAPTCHA也就是用作人机验证。

## 狗与猫数据集准备

- [点击下载即可](https://pan.baidu.com/s/1XW9oqrTaQMB2W3Goeo5ajQ)     提取码：`wa14`

下载解压后目录结构如下：

![image-20201125201214420](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201125201214420.png)

<!-- more -->

本教程只会用到train文件夹，解压后得到如下文件结构：其中包含25,000个猫和狗的.jpg文件。照片用文件名标记，并带有“*狗*”或“*猫*”字样。文件命名约定如下：

![image-20201123192027237](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123192027237.png)

### 绘制猫和狗的照片

查看目录中的几张随机照片，您会发现这些照片是彩色的，并且具有不同的形状和大小。

可以写个小demo，让在pycharm中加载并绘制狗的前九张照片。

完整代码示例如下：

```python
# plot dog photos from the dogs vs cats dataset
from matplotlib import pyplot
from matplotlib.image import imread
# define location of dataset
folder = 'train/'
# plot first few images
for i in range(9):
	# define subplot
	pyplot.subplot(330 + 1 + i)
	# define filename
	filename = folder + 'cat.' + str(i) + '.jpg'
	# load image pixels
	image = imread(filename)
	# plot raw pixel data
	pyplot.imshow(image)
# show the figure
pyplot.show()
```

运行后将创建一个图，显示数据集中狗的前九张照片。

可以看到有些照片是横向格式，有些是肖像格式，有些是正方形。

![image-20201123192218265](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123192218265.png)

### 选择标准照片尺寸

输入越小，意味着模型的训练速度就越快。通常这种想法决定了在建模时会如何选择图像尺寸。因此，将采用这种方法并选择200×200像素的固定大小。

### 将照片预处理成标准目录

可以使用*Keras* [ImageDataGenerator类](https://keras.io/preprocessing/image/)和*flow_from_directory（）* API逐步加载图像。该API希望将数据划分为单独的*train /*和*test /*目录，并希望在每个目录下为每个类都划分一个子目录，例如*train / dog /*和*train / cat /*子目录。对于测试集也是同样的的。然后将图像放在子目录下。为了方便，可以编写脚本来创建具有此首选结构的数据集副本。随机选择25％的图像（或6,250张）用于测试数据集中。

首先，需要创建目录结构，如下所示：

```
dataset_dogs_vs_cats
├── test
│   ├── cats
│   └── dogs
└── train
    ├── cats
    └── dogs
```

可以使用*makedirs（）*函数在Python中创建目录，并使用循环为*train /*和*test /*目录创建*dog /*和*cat /*子目录。

```python
# create directories
dataset_home = 'dataset_dogs_vs_cats/'
subdirs = ['train/', 'test/']
for subdir in subdirs:
	# create label subdirectories
	labeldirs = ['dogs/', 'cats/']
	for labldir in labeldirs:
		newdir = dataset_home + subdir + labldir
		makedirs(newdir, exist_ok=True)
```

接下来，可以枚举数据集中的所有图像文件，然后根据其文件*名将*它们复制到*dogs /*或*cats /*子目录中。

```python
# seed random number generator
seed(1)
# define ratio of pictures to use for validation
val_ratio = 0.25
# copy training dataset images into subdirectories
src_directory = 'train/'
for file in listdir(src_directory):
	src = src_directory + '/' + file
	dst_dir = 'train/'
	if random() < val_ratio:
		dst_dir = 'test/'
	if file.startswith('cat'):
		dst = dataset_home + dst_dir + 'cats/'  + file
		copyfile(src, dst)
	elif file.startswith('dog'):
		dst = dataset_home + dst_dir + 'dogs/'  + file
		copyfile(src, dst)
```

接着，随机决定将25％的图像保留到测试数据集中。

```python
# seed random number generator
seed(1)
# define ratio of pictures to use for validation
val_ratio = 0.25
# copy training dataset images into subdirectories
src_directory = 'train/'
for file in listdir(src_directory):
	src = src_directory + '/' + file
	dst_dir = 'train/'
	if random() < val_ratio:
		dst_dir = 'test/'
	if file.startswith('cat'):
		dst = dataset_home + dst_dir + 'cats/'  + file
		copyfile(src, dst)
	elif file.startswith('dog'):
		dst = dataset_home + dst_dir + 'dogs/'  + file
		copyfile(src, dst)
```

完整的代码示例在下面列出：

```python
# organize dataset into a useful structure
from os import makedirs
from os import listdir
from shutil import copyfile
from random import seed
from random import random
# create directories
dataset_home = 'dataset_dogs_vs_cats/'
subdirs = ['train/', 'test/']
for subdir in subdirs:
	# create label subdirectories
	labeldirs = ['dogs/', 'cats/']
	for labldir in labeldirs:
		newdir = dataset_home + subdir + labldir
		makedirs(newdir, exist_ok=True)
# seed random number generator
seed(1)
# define ratio of pictures to use for validation
val_ratio = 0.25
# copy training dataset images into subdirectories
src_directory = 'train/'
for file in listdir(src_directory):
	src = src_directory + '/' + file
	dst_dir = 'train/'
	if random() < val_ratio:
		dst_dir = 'test/'
	if file.startswith('cat'):
		dst = dataset_home + dst_dir + 'cats/'  + file
		copyfile(src, dst)
	elif file.startswith('dog'):
		dst = dataset_home + dst_dir + 'dogs/'  + file
		copyfile(src, dst)
```

运行该示例之后，您现在将拥有一个新的*dataset_dogs_vs_cats /*目录，其中包含*train /*和*val /*子文件夹，以及更多的*dogs /* can *cats /*子目录，完全符合*Keras* [ImageDataGenerator类](https://keras.io/preprocessing/image/)的设计要求。

:artificial_satellite:也可以选择预先将图片加载到内存中，但是有的机器内存会不支持。比如这个数据集要最少16g的计算机内存才能完全加载。有兴趣的请移步[查看详情:](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/)

## 开发Baseline CNN模型

在本节中，可以为狗对猫数据集开发基线卷积神经网络模型。

Baseline模型将建立可与所有其他模型进行比较的最低模型性能，以及可作为研究和改进基础的模型体系结构。

一个良好的起点是VGG模型的一般架构原理。这些是一个很好的起点，因为它们在ILSVRC 2014竞赛中获得了最佳性能，并且该架构的模块化结构易于理解和实施。有关VGG模型的更多详细信息，请参见2015年论文“[用于大规模图像识别的超深度卷积网络](https://arxiv.org/abs/1409.1556)”。

该体系结构包括使用3×3小型滤波器堆叠卷积层，然后是最大池化层。这些层一起形成一个块，并且可以重复这些块，其中每个块中的过滤器数量随网络深度的增加而增加，例如对于模型的前四个块而言为32、64、128、256。卷积层上使用填充，以确保输出要素图的高度和宽度形状与输入相匹配。

可以在“狗与猫”问题上探索这种架构，并将具有1、2和3个块的这种架构的模型进行比较。

每层将使用[ReLU激活功能](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)和He权重初始化，这通常是最佳做法。例如，可以在Keras中定义3块VGG样式的体系结构，其中每个块具有单个卷积和池化层，如下所示：

```python
# block 1
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
model.add(MaxPooling2D((2, 2)))
# block 2
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
# block 3
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
```

可以创建一个名为*define_model（）*的函数，该函数将定义一个模型并将其返回以拟合数据集。然后可以自定义此功能以定义不同的基线模型，例如具有1个，2个或3个VGG样式块的模型版本。

该模型将拟合随机梯度下降，将从0.001的保守学习率和0.9的动量开始。

问题是二进制分类任务，需要预测0或1的一个值。将使用具有1个节点和S型激活的输出层，并且将使用二进制交叉熵损失函数来优化模型。

以下是*define_model（）*函数的一个示例，该函数使用一个vgg样式的块为狗与猫的问题定义卷积神经网络模型。

```python
# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

可以根据需要调用它来准备模型，例如：

```python
# define model
model = define_model()
```

接下来，需要准备数据。

这涉及到首先定义*ImageDataGenerator*的实例，该实例会将像素值缩放到0-1的范围。

```python
# create data generator
datagen = ImageDataGenerator(rescale=1.0/255.0)
```

接下来，需要为训练和测试数据集准备迭代器。

可以在数据生成器上使用*flow_from_directory（）*函数，并为每个*train /*和*test /*目录创建一个迭代器。必须通过“ *class_mode* ”参数指定该问题是二进制分类问题，并通过“ *target_size* ”参数加载大小为200×200像素的图像。将批量大小固定为64。

```python
# prepare iterators
train_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
	class_mode='binary', batch_size=64, target_size=(200, 200))
test_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
	class_mode='binary', batch_size=64, target_size=(200, 200))
```

然后，可以使用训练迭代器（*train_it*）拟合模型，并在训练期间将测试迭代器（*test_it*）用作验证数据集。

必须指定训练迭代器和测试迭代器的步骤数。这是将组成一个时期的批次数量。可以通过每个迭代器的长度来指定，这将是训练目录和测试目录中图像的总数除以批处理大小（64）。

该模型将拟合20个时期，少量会检查模型是否可以了解问题。

```python
# fit model
history = model.fit_generator(train_it, steps_per_epoch=len(train_it),
	validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)
```

拟合后，可以直接在测试数据集上评估最终模型，并报告分类准确性

```python
# evaluate model
_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)
print('> %.3f' % (acc * 100.0))
```

最后，可以创建训练期间收集的历史图，并将其存储在从*fit_generator（）*调用返回的“ *history* ”目录中。

历史记录包含每个时期末测试和训练数据集上的模型准确性和损失。这些度量在训练时期上的折线图提供了学习曲线，可以用来了解模型是过度拟合，欠拟合还是具有良好拟合。

下面的*summary_diagnostics（）*函数采用历史记录目录，并创建一个带有损失线图的单一图形，另一个用于精度图。然后，根据脚本名称将图形保存到文件名中。如果希望评估模型在不同文件中的多种变化并为每个文件自动创建线图，这将很有帮助。

```python
# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()
```

可以将所有这些结合到一个简单的测试工具中，以测试模型配置。

下面列出了在猫和猫数据集上评估一个整体基线模型的完整示例。

```python
# baseline model for the dogs vs cats dataset
import sys
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model

# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

# run the test harness for evaluating a model
def run_test_harness():
	# define model
	model = define_model()
	# create data generator
	datagen = ImageDataGenerator(rescale=1.0/255.0)
	# prepare iterators
	train_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	test_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	# fit model
	history = model.fit_generator(train_it, steps_per_epoch=len(train_it),
		validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)
	# evaluate model
	_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)
	print('> %.3f' % (acc * 100.0))
	# learning curves
	summarize_diagnostics(history)

# entry point, run the test harness
run_test_harness()
```

现在有了一个测试工具，让看一下对三个简单基线模型的评估。

### 一区块VGG模型

单块VGG模型具有一个包含32个滤波器的单个卷积层，后跟一个最大池化层。

该模型的*define_model（）*函数已在上一节中定义，但出于完整性考虑，下面再次提供。

```python
# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

首先运行此示例，将打印训练和测试数据集的大小，确认数据集已正确加载。

然后对模型进行拟合和评估，在现代GPU硬件上大约需要20分钟。

```
Found 18697 images belonging to 2 classes.
Found 6303 images belonging to 2 classes.
> 72.331
```

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。



在这种情况下，可以看到该模型在测试数据集上达到了约72％的精度。

还创建了一个图，显示了在火车（蓝色）和测试（橙色）数据集上损失的折线图和模型准确性的折线图。

查看此图，可以看到该模型在约12个时期过度拟合了训练数据集。

![image-20201123194634042](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123194634042.png)

:artificial_satellite:**Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With One VGG Block on the Dogs and Cats Dataset**

### 两块VGG模型

两块VGG模型扩展了一个块模型，并添加了具有64个滤波器的第二个块。

为了完整性，下面提供了此模型的*define_model（）*函数。

```python
pyth# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

再次运行此示例将打印训练和测试数据集的大小，确认数据集已正确加载。

对模型进行拟合和评估，并报告测试数据集的性能。

```python
Found 18697 images belonging to 2 classes.
Found 6303 images belonging to 2 classes.
> 76.646
```

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。



在这种情况下，可以看到该模型的性能从一个块的约72％改进为两个块的约76％的性能方面的微小改进

回顾学习曲线的图，可以再次看到，该模型似乎已经过拟合训练数据集，也许很快，在这种情况下，大约是在八个训练时期。

这可能是模型容量增加的结果，可以预期，过快拟合的趋势将在下一个模型中继续。

![Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Two VGG Block on the Dogs and Cats Dataset](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123195050422.png)

:artificial_satellite:**Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Two VGG Block on the Dogs and Cats Dataset**

### 三块VGG模型

三块VGG模型扩展了两个块模型，并添加了具有128个过滤器的第三个块。

该模型的*define_model（）*函数已在上一节中定义，但出于完整性考虑，下面再次提供。

```python
# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

运行此示例将打印训练和测试数据集的大小，并确认数据集已正确加载。

对模型进行拟合和评估，并报告测试数据集的性能。

```python
Found 18697 images belonging to 2 classes.
Found 6303 images belonging to 2 classes.
> 80.184
```

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。



在这种情况下，可以看到性能进一步提高，从两个块的约76％提高到三个块的约80％精度。这个结果很好，因为它接近于论文中报道的使用SVM的现有技术，准确度约为82％。

回顾学习曲线图，可以看到类似的过度拟合趋势，在这种情况下，可能会推迟到第五或第六个时代。

![image-20201123195050422](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123195050422.png)

:artificial_satellite:**Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Three VGG Block on the Dogs and Cats Dataset**

## 讨论区

已经探索了基于VGG架构的三种不同模型。

结果可以总结如下，尽管鉴于算法的随机性质，必须在这些结果中假设一些差异：

- **VGG 1**：72.331％
- **VGG 2**：76.646％
- **VGG 3**：80.184％

随着容量的增加，看到了性能改善的趋势，但是在运行的早期和早期，也出现了过拟合的情况。

结果表明该模型可能会受益于正则化技术。这可能包括诸如Dropout，权重衰减和数据增强之类的技术。后者还可以通过鼓励模型学习通过扩展训练数据集学习位置进一步不变的特征来提高性能。

## 开发模型改进

在上一节中，使用VGG样式的模块开发了基线模型，并发现了随着模型容量的增加而性能提高的趋势。

在本节中，将从具有三个VGG块（即VGG 3）的基线模型开始，并探索对该模型的一些简单改进。

通过查看训练期间模型的学习曲线，模型显示出过度拟合的强烈迹象。可以探索两种尝试解决这种过度拟合的方法：[Dropout正则化](https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/)和[数据扩充](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)。

预计这两种方法都会减慢训练过程中的改进速度，并有望解决[训练数据集](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/)的[过拟合问题](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/)。因此，会将训练时期的数量从20个增加到50个，以便为模型提供更多的优化空间。

## [Dropout正则化](https://www.jianshu.com/p/257d3da535ab)

Dropout正则化是对深度神经网络进行正则化的一种廉价计算方法。

Dropout是通过概率性地删除或“*放弃*”对某个层的输入来进行的，该输入可以是数据样本中的输入变量或来自上一层的激活。它具有模拟具有非常不同的网络结构的大量网络的效果，进而使网络中的节点通常对输入更为健壮。

有关Dropout的更多信息，请参见以下文章：

- [如何通过Keras中的Dropout正则化来减少过度拟合](https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/)

以下是*define_model（）*函数，用于添加了Dropout的基线模型的更新版本。在这种情况下，在每个VGG块之后应用20％的Dropout，而在模型的分类器部分中的完全连接层之后应用50％的较大Dropout率。

```python
# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dropout(0.5))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

为了完整起见，下面列出了基线模型的完整代码列表，以及在狗对猫数据集上添加了Dropout信息的信息。

```python
# baseline model with dropout for the dogs vs cats dataset
import sys
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Dropout
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dropout(0.5))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model

# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

# run the test harness for evaluating a model
def run_test_harness():
	# define model
	model = define_model()
	# create data generator
	datagen = ImageDataGenerator(rescale=1.0/255.0)
	# prepare iterator
	train_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	test_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	# fit model
	history = model.fit_generator(train_it, steps_per_epoch=len(train_it),
		validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)
	# evaluate model
	_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)
	print('> %.3f' % (acc * 100.0))
	# learning curves
	summarize_diagnostics(history)

# entry point, run the test harness
run_test_harness()
```

运行示例首先拟合模型，然后在保留的测试数据集上报告模型性能。

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。

在这种情况下，可以看到模型性能从Baseline模型的约80％的准确度小幅提升到增加了Dropout的约81％。

```python
Found 18697 images belonging to 2 classes.
Found 6303 images belonging to 2 classes.
> 81.279
```

回顾学习曲线，可以看到Dropout对训练和测试集上模型的改进率都有影响。

尽管性能可能会在运行快结束时开始停止，但过度拟合已被减少或延迟。

结果表明，进一步的训练时期可能会导致模型的进一步改进。除了训练时期的增加之外，探索在VGG阻滞后也许略高的Dropout率也可能很有趣。

![Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Dropout on the Dogs and Cats Dataset](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/03/Line-Plots-of-Loss-and-Accuracy-Learning-Curves-for-the-Baseline-Model-with-Dropout-on-the-Dogs-and-Cats-Dataset.png)

:artificial_satellite:**Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Dropout on the Dogs and Cats Dataset**

### 图像数据增强

图像数据增强是一种可通过在数据集中创建图像的修改版本来人工扩展训练数据集大小的技术。

在更多数据上训练深度学习神经网络模型可以得到更熟练的模型，并且增强技术可以创建图像的变体，从而可以提高拟合模型将其学到的知识概括为新图像的能力。

数据增强还可以充当正则化技术，在训练数据中添加噪声，并鼓励模型学习相同的特征，而不会改变它们在输入中的位置。

对猫和狗的输入照片进行小的更改可能会对此问题有用，例如小移位和水平翻转。可以将这些扩充指定为用于训练数据集的ImageDataGenerator的参数。增强不应用于测试数据集，因为希望评估模型在未修改照片上的性能。

这就要求为训练和测试数据集有一个单独的ImageDataGenerator实例，然后为从相应数据生成器创建的训练和测试集使用迭代器。例如：

```python
# create data generators
train_datagen = ImageDataGenerator(rescale=1.0/255.0,
	width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1.0/255.0)
# prepare iterators
train_it = train_datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
	class_mode='binary', batch_size=64, target_size=(200, 200))
test_it = test_datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
	class_mode='binary', batch_size=64, target_size=(200, 200))
```

在这种情况下，训练数据集中的照片将通过小的（10％）随机水平和垂直偏移以及随机水平翻转来增强，从而创建照片的镜像。训练和测试步骤中的照片将以相同方式缩放其像素值。

为了完整起见，下面列出了带有狗和猫数据集训练数据的基线模型的完整代码列表。

```python
# baseline model with data augmentation for the dogs vs cats dataset
import sys
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dense(1, activation='sigmoid'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model

# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

# run the test harness for evaluating a model
def run_test_harness():
	# define model
	model = define_model()
	# create data generators
	train_datagen = ImageDataGenerator(rescale=1.0/255.0,
		width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
	test_datagen = ImageDataGenerator(rescale=1.0/255.0)
	# prepare iterators
	train_it = train_datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	test_it = test_datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
		class_mode='binary', batch_size=64, target_size=(200, 200))
	# fit model
	history = model.fit_generator(train_it, steps_per_epoch=len(train_it),
		validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)
	# evaluate model
	_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)
	print('> %.3f' % (acc * 100.0))
	# learning curves
	summarize_diagnostics(history)

# entry point, run the test harness
run_test_harness()
```

运行示例首先拟合模型，然后在保留的测试数据集上报告模型性能。

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。

在这种情况下，通过简单的数据扩充，可以看到性能从Baseline模型的约80％上升到Baseline模型的约85％约5％。

```
> 85.816
```

回顾学习曲线，发现该模型似乎能够进一步学习，即使在运行结束时，火车和测试数据集上的损失仍在减少。以100个或更多的时间段重复实验，很可能会产生更好的模型。

探索可能进一步鼓励学习与输入中位置无关的特征的其他增强（例如较小的旋转和缩放）可能很有趣。

![image-20201123195618687](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/20202020image-20201123195618687.png)

**:artificial_satellite:Line Plots of Loss and Accuracy Learning Curves for the Baseline Model With Data Augmentation on the Dogs and Cats Dataset**

### 讨论区

探索了对基线模型的三种不同改进。

结果可以总结如下，尽管鉴于算法的随机性质，必须在这些结果中假设一些差异：

- **BaselineVGG3** +Dropout率：81.279％
- **BaselineVGG3** +数据增强：85.816

令人怀疑的是，添加正则化技术会减慢学习算法的进度并减少过度拟合，从而提高了保持数据集的性能。两种方法的结合以及训练时期数量的进一步增加可能会导致进一步的改进。

这仅仅是可以在此数据集上探索的改进类型的开始。除了调整所描述的正则化方法外，还可以探索其他正则化方法，例如[体重减轻](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/)和[提早停止](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)。

可能值得探索学习算法的变化，例如[学习率的](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/)变化，学习率时间表的使用或自适应学习率（例如[Adam）](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)。

替代模型架构也可能值得探讨。预期所选择的Baseline模型将提供比此问题所需的容量更多的容量，并且较小的模型可能会更快地训练，进而可能导致更好的性能。

## 探索迁移学习

迁移学习包括 **使用经过相关任务训练的模型的全部或部分。**

Keras提供了一系列预训练的模型，这些模型可以通过[Keras Applications API](https://keras.io/applications/)完全或部分加载和使用。

迁移学习的有用模型是VGG模型之一，例如具有16层的VGG-16，该模型在开发时就在ImageNet照片分类挑战中取得了最佳成绩。

该模型由两个主要部分组成，该模型的特征提取器部分由VGG块组成，该模型的分类器部分由完全连接的层和输出层组成。

可以使用模型的特征提取部分，并添加模型的新分类器部分，该部分针对狗和猫的数据集量身定制。具体来说，可以在训练过程中将所有卷积层的权重保持固定，并且仅训练新的完全连接的层，这些层将学习解释从模型中提取的特征并进行二进制分类。

这可以通过加载[VGG-16模型](https://keras.io/applications/#vgg16)，从[模型](https://keras.io/applications/#vgg16)的输出端删除完全连接的层，然后添加新的完全连接的层来解释模型输出并进行预测来实现。通过将“ *include_top* ”参数设置为“ *False* ”，可以自动删除模型的分类器部分，在这种情况下，这也需要为模型指定输入的形状（224、224、3）。这意味着加载的模型在最后一个最大池化层结束，之后可以手动添加*Flatten*层和新的clasifier层。

下面的*define_model（）*函数实现了此功能，并返回一个准备好进行训练的新模型。

```python
# define cnn model
def define_model():
	# load model
	model = VGG16(include_top=False, input_shape=(224, 224, 3))
	# mark loaded layers as not trainable
	for layer in model.layers:
		layer.trainable = False
	# add new classifier layers
	flat1 = Flatten()(model.layers[-1].output)
	class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)
	output = Dense(1, activation='sigmoid')(class1)
	# define new model
	model = Model(inputs=model.inputs, outputs=output)
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model
```

创建完成后，可以像以前一样在训练数据集上训练模型。

在这种情况下，不需要太多的训练，因为只有新的完全连接的输出层才具有可训练的权重。因此，会将训练时期数固定为10。

VGG16模型是在特定的ImageNet挑战数据集上训练的。这样，它被配置为期望输入图像具有224×224像素的形状。从猫猫数据集中加载照片时，将以此为目标尺寸。

该模型还希望图像居中。也就是说，要从输入中减去ImageNet训练数据集上计算出的每个通道（红色，绿色和蓝色）的平均像素值。Keras通过*preprocess_input（）*函数为单个照片提供了准备功能。尽管如此，通过将“ *featurewise_center* ”参数设置为“ *True* ”，并手动指定要居中作为ImageNet训练数据集中的平均值使用的平均像素值，可以使用ImageDataGenerator达到相同的效果：[123.68，116.779，103.939] 。

下面列出了用于在狗对猫数据集中进行迁移学习的VGG模型的完整代码列表。

```python
# vgg16 model used for transfer learning on the dogs and cats dataset
import sys
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

# define cnn model
def define_model():
	# load model
	model = VGG16(include_top=False, input_shape=(224, 224, 3))
	# mark loaded layers as not trainable
	for layer in model.layers:
		layer.trainable = False
	# add new classifier layers
	flat1 = Flatten()(model.layers[-1].output)
	class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)
	output = Dense(1, activation='sigmoid')(class1)
	# define new model
	model = Model(inputs=model.inputs, outputs=output)
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model

# plot diagnostic learning curves
def summarize_diagnostics(history):
	# plot loss
	pyplot.subplot(211)
	pyplot.title('Cross Entropy Loss')
	pyplot.plot(history.history['loss'], color='blue', label='train')
	pyplot.plot(history.history['val_loss'], color='orange', label='test')
	# plot accuracy
	pyplot.subplot(212)
	pyplot.title('Classification Accuracy')
	pyplot.plot(history.history['accuracy'], color='blue', label='train')
	pyplot.plot(history.history['val_accuracy'], color='orange', label='test')
	# save plot to file
	filename = sys.argv[0].split('/')[-1]
	pyplot.savefig(filename + '_plot.png')
	pyplot.close()

# run the test harness for evaluating a model
def run_test_harness():
	# define model
	model = define_model()
	# create data generator
	datagen = ImageDataGenerator(featurewise_center=True)
	# specify imagenet mean values for centering
	datagen.mean = [123.68, 116.779, 103.939]
	# prepare iterator
	train_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',
		class_mode='binary', batch_size=64, target_size=(224, 224))
	test_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',
		class_mode='binary', batch_size=64, target_size=(224, 224))
	# fit model
	history = model.fit_generator(train_it, steps_per_epoch=len(train_it),
		validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)
	# evaluate model
	_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)
	print('> %.3f' % (acc * 100.0))
	# learning curves
	summarize_diagnostics(history)

# entry point, run the test harness
run_test_harness()
```

运行示例首先拟合模型，然后在保留的测试数据集上报告模型性能。

**注意**：由于算法或评估程序的随机性，或者数值精度不同，您的[结果可能会有所](https://machinelearningmastery.com/different-results-each-time-in-machine-learning/)不同。考虑运行该示例几次并比较平均结果。

在这种情况下，可以看到该模型在保留测试数据集上的分类精度达到了约97％，取得了令人印象深刻的结果。

```python
Found 18697 images belonging to 2 classes.
Found 6303 images belonging to 2 classes.
> 97.636
```

回顾学习曲线，可以看到该模型快速拟合了数据集。尽管结果表明分类器中的附加功能和/或使用正则化可能会有所帮助，但它并没有显示出过度拟合的能力。

可以对该方法进行许多改进，包括向模型的分类器部分添加Dropout正则化，甚至可能微调模型的特征检测器部分中某些或所有层的权重。

![image-20201123195947940](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020image-20201123195947940.png)

**:artificial_satellite:Line Plots of Loss and Accuracy Learning Curves for the VGG16 Transfer Learning Model on the Dogs and Cats Dataset**

## 如何最终确定模型并做出预测

只要有继续改进的想法以及进行测试的时间和资源，模型改进的过程就可以持续进行。

在某个时候，必须选择并采用最终的模型配置。为了节约时间，下面会直接使用VGG-16迁移学习方法作为最终模型。

首先，将通过在整个训练数据集上拟合模型并将模型保存到文件中以供以后使用来最终确定模型。然后，将加载保存的模型，并使用它对单个图像进行预测。

### 准备最终数据集

最终模型通常适合所有可用数据，例如所有训练和测试数据集的组合。

在本教程中，将展示仅适用于训练数据集的最终模型，因为只有训练数据集的标签。

第一步是准备训练数据集，以便*ImageDataGenerator*类可以通过*flow_from_directory（）*函数将其加载。具体来说，需要创建一个新目录，其中所有训练图像都组织在*dog /*和*cat /*子目录中，而没有任何分离到*train /*或*test /*目录中。

这可以通过更新在教程开始时开发的脚本来实现。

目录结构如下所示：

```python
finalize_dogs_vs_cats
├── cats
└── dogs
```

为了完整性，下面列出了完整的脚本。

```python
# organize dataset into a useful structure
from os import makedirs
from os import listdir
from shutil import copyfile
# create directories
dataset_home = 'finalize_dogs_vs_cats/'
# create label subdirectories
labeldirs = ['dogs/', 'cats/']
for labldir in labeldirs:
	newdir = dataset_home + labldir
	makedirs(newdir, exist_ok=True)
# copy training dataset images into subdirectories
src_directory = 'dogs-vs-cats/train/'
for file in listdir(src_directory):
	src = src_directory + '/' + file
	if file.startswith('cat'):
		dst = dataset_home + 'cats/'  + file
		copyfile(src, dst)
	elif file.startswith('dog'):
		dst = dataset_home + 'dogs/'  + file
		copyfile(src, dst)
```

### 保存最终模型

现在，准备将最终模型拟合到整个训练数据集上。

该*flow_from_directory（）*必须更新加载的所有图像从新的*finalize_dogs_vs_cats /*目录。

```python
# prepare iterator
train_it = datagen.flow_from_directory('finalize_dogs_vs_cats/',
	class_mode='binary', batch_size=64, target_size=(224, 224))
```

另外，对*fit_generator（）*的调用不再需要指定验证数据集。

```python
# fit model
model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)
```

一旦拟合，可以通过在模型上调用*save（）*函数并将最终的文件名传入来将最终模型保存到H5文件中。

```python
# save model
model.save('final_model.h5')
```

注意，保存和加载[Keras](https://www.h5py.org/)模型需要在电脑上安装[h5py库](https://www.h5py.org/)。

下面列出了将最终模型拟合到训练数据集并将其保存到文件的完整示例。

```python
# save the final model to file
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

# define cnn model
def define_model():
	# load model
	model = VGG16(include_top=False, input_shape=(224, 224, 3))
	# mark loaded layers as not trainable
	for layer in model.layers:
		layer.trainable = False
	# add new classifier layers
	flat1 = Flatten()(model.layers[-1].output)
	class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)
	output = Dense(1, activation='sigmoid')(class1)
	# define new model
	model = Model(inputs=model.inputs, outputs=output)
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
	return model

# run the test harness for evaluating a model
def run_test_harness():
# define model
	model = define_model()
	# create data generator
	datagen = ImageDataGenerator(featurewise_center=True)
	# specify imagenet mean values for centering
	datagen.mean = [123.68, 116.779, 103.939]
	# prepare iterator
	train_it = datagen.flow_from_directory('finalize_dogs_vs_cats/',
		class_mode='binary', batch_size=64, target_size=(224, 224))
	# fit model
	model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)
	# save model
	model.save('final_model.h5')

# entry point, run the test harness
run_test_harness()
```

运行此示例之后，您现在将在当前工作目录中有一个名为' *final_model.h5* '的大文件，大小为81 MB 。

### 做出预测

可以使用保存的模型对新图像进行预测。

该模型假定新图像是彩色的，并且已经对其进行了分割，因此一张图像至少包含一只狗或猫。

下图是从猫和狗比赛的测试数据集中提取的图像。它没有标签，但可以清楚地看出它是狗的照片。您可以使用文件名“ *sample_image.jpg* ”将其保存在当前工作目录中。

![Dog](https://cdn.jsdelivr.net/gh/John-tlh/blog/images/2020sample_image.jpg)

:artificial_satellite:**Dog (sample_image.jpg)**

假装这是一个全新的，看不见的图像。

注意：图像的子目录（每个类别一个*）*由*flow_from_directory（）*函数按字母顺序加载，并为每个类别分配一个整数。子目录“ *cat* ”位于“ *dog* ”之前，因此为类标签分配了整数：*cat = 0，dog = 1*。训练模型时，可以通过调用*flow_from_directory（）中*的“ *classes* ”参数来更改此设置。

首先，可以加载图像并将其强制为224×224像素。然后可以调整加载的图像的大小，以在数据集中具有单个样本。像素值也必须居中以匹配模型训练期间准备数据的方式。该*load_image（）*函数实现这一点，将返回加载图像准备进行分类。

```python
# load and prepare the image
def load_image(filename):
	# load the image
	img = load_img(filename, target_size=(224, 224))
	# convert to array
	img = img_to_array(img)
	# reshape into a single sample with 3 channels
	img = img.reshape(1, 224, 224, 3)
	# center pixel data
	img = img.astype('float32')
	img = img - [123.68, 116.779, 103.939]
	return img
```

接下来，可以像上一节中那样加载模型，并调用predict（）函数以将图像中的内容分别预测为“*猫*”和“*狗*”的“ *0* ”和“ *1* ”之间的数字。

```python
# predict the class
result = model.predict(img)
```

完整代码示例如下：

```python
# make a prediction for a new image.
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.models import load_model

# load and prepare the image
def load_image(filename):
	# load the image
	img = load_img(filename, target_size=(224, 224))
	# convert to array
	img = img_to_array(img)
	# reshape into a single sample with 3 channels
	img = img.reshape(1, 224, 224, 3)
	# center pixel data
	img = img.astype('float32')
	img = img - [123.68, 116.779, 103.939]
	return img

# load an image and predict the class
def run_example():
	# load the image
	img = load_image('sample_image.jpg')
	# load model
	model = load_model('final_model.h5')
	# predict the class
	result = model.predict(img)
	print(result[0])

# entry point, run the example
run_example()
```

运行示例将首先加载并准备图像，加载模型，然后正确地预测加载的图像代表“*狗*”或“ *1*类”。

```
1
```
